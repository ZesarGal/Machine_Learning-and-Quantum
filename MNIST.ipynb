{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alice, Bob, and Daniel are friends learning machine learning together. After watching a few lectures, they are very proud of having learned many useful tools, including linear and logistic regression, non-linear features, regularization, and kernel tricks. To see how these methods can be used to solve a real life problem, they decide to get their hands dirty with the famous digit recognition problem using the MNIST (Mixed National Institute of Standards and Technology) database.\n",
    "\n",
    "The MNIST database contains binary images of handwritten digits commonly used to train image processing systems. The digits were collected from among Census Bureau employees and high school students. The database contains 60,000 training digits and 10,000 testing digits, all of which have been size-normalized and centered in a fixed-size image of 28 Ã— 28 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"..\")\n",
    "from utils import *\n",
    "from svm import *\n",
    "from kernel import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_MNIST_data():\n",
    "    \"\"\"\n",
    "    Reads mnist dataset from file\n",
    "\n",
    "    Returns:\n",
    "        train_x - 2D Numpy array (n, d) where each row is an image\n",
    "        train_y - 1D Numpy array (n, ) where each row is a label\n",
    "        test_x  - 2D Numpy array (n, d) where each row is an image\n",
    "        test_y  - 1D Numpy array (n, ) where each row is a label\n",
    "\n",
    "    \"\"\"\n",
    "    train_set, valid_set, test_set = read_pickle_data('mnist.pkl.gz')\n",
    "    train_x, train_y = train_set\n",
    "    valid_x, valid_y = valid_set\n",
    "    train_x = np.vstack((train_x, valid_x))\n",
    "    train_y = np.append(train_y, valid_y)\n",
    "    test_x, test_y = test_set\n",
    "    return (train_x, train_y, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_x, train_y, test_x, test_y = get_MNIST_data()\n",
    "# Plot the first 20 images of the training set.\n",
    "plot_images(train_x[0:20, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To solve the linear regression problem, you recall the linear regression has a closed form solution:\n",
    "    $$\\displaystyle  \\displaystyle \\theta = (X^ T X + \\lambda I)^{-1} X^ T Y.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closed_form(X, Y, lambda_factor):\n",
    "    \"\"\"\n",
    "    Computes the closed form solution of linear regression with L2 regularization\n",
    "    Args:\n",
    "        X - (n, d + 1) NumPy array (n datapoints each with d features plus the bias feature in the first dimension)\n",
    "        Y - (n, ) NumPy array containing the labels (a number from 0-9) for each\n",
    "            data point\n",
    "        lambda_factor - the regularization constant (scalar)\n",
    "    Returns:\n",
    "        theta - (d + 1, ) NumPy array containing the weights of linear regression. Note that theta[0]\n",
    "        represents the y-axis intercept of the model and therefore X[0] = 1\n",
    "    \"\"\"\n",
    "    theta = np.linalg.inv(X.T.dot(X) + lambda_factor*np.eye(X.shape[1])).dot(X.T).dot(Y)\n",
    "    \n",
    "    return theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_error_linear(test_x, Y, theta):\n",
    "    test_y_predict = np.round(np.dot(test_x, theta))\n",
    "    test_y_predict[test_y_predict < 0] = 0\n",
    "    test_y_predict[test_y_predict > 9] = 9\n",
    "    return 1 - np.mean(test_y_predict == Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_linear_regression_on_MNIST(lambda_factor=1):\n",
    "    \"\"\"\n",
    "    Trains linear regression, classifies test data, computes test error on test set\n",
    "\n",
    "    Returns:\n",
    "        Final test error\n",
    "    \"\"\"\n",
    "    train_x, train_y, test_x, test_y = get_MNIST_data()\n",
    "    train_x_bias = np.hstack([np.ones([train_x.shape[0], 1]), train_x])\n",
    "    test_x_bias = np.hstack([np.ones([test_x.shape[0], 1]), test_x])\n",
    "    theta = closed_form(train_x_bias, train_y, lambda_factor)\n",
    "    test_error = compute_test_error_linear(test_x_bias, test_y, theta)\n",
    "    return test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_linear_regression_on_MNIST()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alice and you find that no matter what $\\lambda$ factor you try, the test error is large. With some thinking, you realize that something is wrong with this approach: The closed form solution of linear regression is the solution of optimizing the mean squared error loss. This is not an appropriate loss function for a classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bob thinks it is clearly not a regression problem, but a classification problem. He thinks that we can change it into a binary classification and use the support vector machine we learned in Lecture 4 to solve the problem. In order to do so, he suggests that we can build an one vs. rest model for every digit. For example, classifying the digits into two classes: 0 and not 0.\n",
    "\n",
    "Bob wrote a function run_svm_one_vs_rest_on_MNIST where he changed the labels of digits 1-9 to 1 and keeps the label 0 for digit 0. He also found that sklearn package contains an SVM model that you can use directly. He gave you the link to this model and hopes you can tell him how to use that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_vs_rest_svm(train_x, train_y, test_x):\n",
    "    \"\"\"\n",
    "    Trains a linear SVM for binary classifciation\n",
    "    Args:\n",
    "        train_x - (n, d) NumPy array (n datapoints each with d features)\n",
    "        train_y - (n, ) NumPy array containing the labels (0 or 1) for each training data point\n",
    "        test_x - (m, d) NumPy array (m datapoints each with d features)\n",
    "    Returns:\n",
    "        pred_test_y - (m,) NumPy array containing the labels (0 or 1) for each test data point\n",
    "    \"\"\"\n",
    "    svc = LinearSVC(C = 0.1, random_state = 0)\n",
    "    svc.fit(train_x, train_y)\n",
    "    \n",
    "    pred_test_y = svc.predict(test_x)\n",
    "    \n",
    "    return pred_test_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_svm_one_vs_rest_on_MNIST():\n",
    "    \"\"\"\n",
    "    Trains svm, classifies test data, computes test error on test set\n",
    "\n",
    "    Returns:\n",
    "        Test error for the binary svm\n",
    "    \"\"\"\n",
    "    train_x, train_y, test_x, test_y = get_MNIST_data()\n",
    "    train_y[train_y != 0] = 1\n",
    "    test_y[test_y != 0] = 1\n",
    "    pred_test_y = one_vs_rest_svm(train_x, train_y, test_x)\n",
    "    test_error = compute_test_error_svm(test_y, pred_test_y)\n",
    "    return test_error\n",
    "\n",
    "\n",
    "print('SVM one vs. rest test_error:', run_svm_one_vs_rest_on_MNIST())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C represents the tolerance of error. A larger C means we are punishing more on the classification error, thus being less tolerant to misclassifications. Therefore, we will get a smaller margin hyperplane.\n",
    "\n",
    "- Larger C gives smaller tolerance of violation.\n",
    "\n",
    "- Larger C gives a smaller-margin separating hyperplane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_class_svm(train_x, train_y, test_x):\n",
    "    \"\"\"\n",
    "    Trains a linear SVM for multiclass classifciation using a one-vs-rest strategy\n",
    "    Args:\n",
    "        train_x - (n, d) NumPy array (n datapoints each with d features)\n",
    "        train_y - (n, ) NumPy array containing the labels (int) for each training data point\n",
    "        test_x - (m, d) NumPy array (m datapoints each with d features)\n",
    "    Returns:\n",
    "        pred_test_y - (m,) NumPy array containing the labels (int) for each test data point\n",
    "    \"\"\"\n",
    "    clf = LinearSVC(C = 0.1, random_state = 0)\n",
    "    clf.fit(train_x, train_y)\n",
    "    \n",
    "    pred_test_y = clf.predict(test_x)\n",
    "    \n",
    "    return pred_test_y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_multiclass_svm_on_MNIST():\n",
    "    \"\"\"\n",
    "    Trains svm, classifies test data, computes test error on test set\n",
    "\n",
    "    Returns:\n",
    "        Test error for the binary svm\n",
    "    \"\"\"\n",
    "    train_x, train_y, test_x, test_y = get_MNIST_data()\n",
    "    pred_test_y = multi_class_svm(train_x, train_y, test_x)\n",
    "    test_error = compute_test_error_svm(test_y, pred_test_y)\n",
    "    return test_error\n",
    "\n",
    "\n",
    "print('Multiclass SVM test_error:', run_multiclass_svm_on_MNIST())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multinomial (Softmax) Regression and Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daniel suggests that instead of building ten models, we can expand a single logistic regression model into a multinomial regression and solve it with similar gradient descent algorithm.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each data points $x^{(i)}$, we want compute the probability that $x^{(i)}$ is labeled as $j$ for $j=0,1,\\dots, k-1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Title](comprob.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import coo_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computes, for each datapoint $X[i]$, the probability that $X[i]$ is labeled as $j$ for $j = 0, 1, \\dots , k-1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_probabilities(X, theta, temp_parameter):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        X - (n, d) NumPy array (n datapoints each with d features)\n",
    "        theta - (k, d) NumPy array, where row j represents the parameters of our model for label j\n",
    "        temp_parameter - the temperature parameter of softmax function (scalar)\n",
    "    Returns:\n",
    "        H - (k, n) NumPy array, where each entry H[j][i] is the probability that X[i] is labeled as j\n",
    "    \"\"\"\n",
    "    a = (theta @ X.T) / temp_parameter\n",
    "    c = np.max(a, axis=0)\n",
    "    z = a - c\n",
    "    exp_z = np.exp(z)\n",
    "    return exp_z/exp_z.sum(axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![cost](cost.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_function(X, Y, theta, lambda_factor, temp_parameter):\n",
    "    \"\"\"\n",
    "    Computes the total cost over every datapoint.\n",
    "\n",
    "    Args:\n",
    "        X - (n, d) NumPy array (n datapoints each with d features)\n",
    "        Y - (n, ) NumPy array containing the labels (a number from 0-9) for each\n",
    "            data point\n",
    "        theta - (k, d) NumPy array, where row j represents the parameters of our\n",
    "                model for label j\n",
    "        lambda_factor - the regularization constant (scalar)\n",
    "        temp_parameter - the temperature parameter of softmax function (scalar)\n",
    "\n",
    "    Returns\n",
    "        c - the cost value (scalar)\n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE\n",
    "    N = X.shape[0]\n",
    "    prob = compute_probabilities(X,theta,temp_parameter)\n",
    "    # for each data point select the probability of corresponding label\n",
    "    # e.g label for image1 = 1 = y1 then out of all P(y1 = 0 | x1, theta) to P(y1 = 9 | x1, theta) select P(y1 = 1 | x1, theta)\n",
    "    # these probabilities are given by compute_probabilities or SoftMax Function\n",
    "    selected_prob = np.choose(Y, prob)  # Shape = [n,]\n",
    "    non_regulized_cost = (- 1/N) * (np.sum(np.log(selected_prob)))\n",
    "    regulized_cost = (lambda_factor/2.0) * (np.sum(np.square(theta)))\n",
    "    return non_regulized_cost + regulized_cost\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![grad1](grad1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![grad2](grad2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_gradient_descent_iteration(X, Y, theta, alpha, lambda_factor, temp_parameter):\n",
    "    \"\"\"\n",
    "    Runs one step of batch gradient descent\n",
    "    Args:\n",
    "        X - (n, d) NumPy array (n datapoints each with d features)\n",
    "        Y - (n, ) NumPy array containing the labels (a number from 0-9) for each\n",
    "            data point\n",
    "        theta - (k, d) NumPy array, where row j represents the parameters of our\n",
    "                model for label j\n",
    "        alpha - the learning rate (scalar)\n",
    "        lambda_factor - the regularization constant (scalar)\n",
    "        temp_parameter - the temperature parameter of softmax function (scalar)\n",
    "    Returns:\n",
    "        theta - (k, d) NumPy array that is the final value of parameters theta\n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE\n",
    "    n = X.shape[0]\n",
    "    probabilities = compute_probabilities(X, theta, temp_parameter)\n",
    "\n",
    "    columns = np.arange(probabilities.shape[1])\n",
    "    data = np.ones(probabilities.shape[1])\n",
    "    one_and_zeros = coo_matrix((data, (Y, columns)), shape = (probabilities.shape[0], probabilities.shape[1])).toarray()\n",
    "    \n",
    "    difference = one_and_zeros - probabilities\n",
    "\n",
    "    gradient = -(1/(n * temp_parameter)) * np.matmul(difference, X) + lambda_factor * theta\n",
    "\n",
    "    theta -= alpha * gradient\n",
    "\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smaller temperature parameter means that there is less variance in our distribution, and larger temperature, more variance. In other words smaller temperature parameter favors larger thetas, and larger temperature parameter makes the distribution more uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_feature_vector(X):\n",
    "    \"\"\"\n",
    "    Adds the x[i][0] = 1 feature for each data point x[i].\n",
    "    Args:\n",
    "        X - a NumPy matrix of n data points, each with d - 1 features\n",
    "    Returns: X_augment, an (n, d) NumPy array with the added feature for each datapoint\n",
    "    \"\"\"\n",
    "    column_of_ones = np.zeros([len(X), 1]) + 1\n",
    "    return np.hstack((column_of_ones, X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_regression(X, Y, temp_parameter, alpha, lambda_factor, k, num_iterations):\n",
    "    \"\"\"\n",
    "    Runs batch gradient descent for a specified number of iterations on a dataset\n",
    "    with theta initialized to the all-zeros array. Here, theta is a k by d NumPy array\n",
    "    where row j represents the parameters of our model for label j for\n",
    "    j = 0, 1, ..., k-1\n",
    "\n",
    "    Args:\n",
    "        X - (n, d - 1) NumPy array (n data points, each with d-1 features)\n",
    "        Y - (n, ) NumPy array containing the labels (a number from 0-9) for each\n",
    "            data point\n",
    "        temp_parameter - the temperature parameter of softmax function (scalar)\n",
    "        alpha - the learning rate (scalar)\n",
    "        lambda_factor - the regularization constant (scalar)\n",
    "        k - the number of labels (scalar)\n",
    "        num_iterations - the number of iterations to run gradient descent (scalar)\n",
    "\n",
    "    Returns:\n",
    "        theta - (k, d) NumPy array that is the final value of parameters theta\n",
    "        cost_function_progression - a Python list containing the cost calculated at each step of gradient descent\n",
    "    \"\"\"\n",
    "    X = augment_feature_vector(X)\n",
    "    theta = np.zeros([k, X.shape[1]])\n",
    "    cost_function_progression = []\n",
    "    for i in range(num_iterations):\n",
    "        cost_function_progression.append(compute_cost_function(X, Y, theta, lambda_factor, temp_parameter))\n",
    "        theta = run_gradient_descent_iteration(X, Y, theta, alpha, lambda_factor, temp_parameter)\n",
    "    return theta, cost_function_progression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Error($T=0.5$)=0.0839\n",
    "- Error($T=1$)=0.1005\n",
    "- Error($T=2$)=0.1261"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we already classified every  as a digit, we could use the model we already trained and just calculate our estimations (mod 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_y(train_y, test_y):\n",
    "    \"\"\"\n",
    "    Changes the old digit labels for the training and test set for the new (mod 3)\n",
    "    labels.\n",
    "\n",
    "    Args:\n",
    "        train_y - (n, ) NumPy array containing the labels (a number between 0-9)\n",
    "                 for each datapoint in the training set\n",
    "        test_y - (n, ) NumPy array containing the labels (a number between 0-9)\n",
    "                for each datapoint in the test set\n",
    "\n",
    "    Returns:\n",
    "        train_y_mod3 - (n, ) NumPy array containing the new labels (a number between 0-2)\n",
    "                     for each datapoint in the training set\n",
    "        test_y_mod3 - (n, ) NumPy array containing the new labels (a number between 0-2)\n",
    "                    for each datapoint in the test set\n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE\n",
    "    return train_y % 3, test_y % 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification(X, theta, temp_parameter):\n",
    "    \"\"\"\n",
    "    Makes predictions by classifying a given dataset\n",
    "    Args:\n",
    "        X - (n, d - 1) NumPy array (n data points, each with d - 1 features)\n",
    "        theta - (k, d) NumPy array where row j represents the parameters of our model for\n",
    "                label j\n",
    "        temp_parameter - the temperature parameter of softmax function (scalar)\n",
    "    Returns:\n",
    "        Y - (n, ) NumPy array, containing the predicted label (a number between 0-9) for\n",
    "            each data point\n",
    "    \"\"\"\n",
    "    X = augment_feature_vector(X)\n",
    "    probabilities = compute_probabilities(X, theta, temp_parameter)\n",
    "    return np.argmax(probabilities, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_error_mod3(X, Y, theta, temp_parameter):\n",
    "    \"\"\"\n",
    "    Returns the error of these new labels when the classifier predicts the digit. (mod 3)\n",
    "\n",
    "    Args:\n",
    "        X - (n, d - 1) NumPy array (n datapoints each with d - 1 features)\n",
    "        Y - (n, ) NumPy array containing the labels (a number from 0-2) for each\n",
    "            data point\n",
    "        theta - (k, d) NumPy array, where row j represents the parameters of our\n",
    "                model for label j\n",
    "        temp_parameter - the temperature parameter of softmax function (scalar)\n",
    "\n",
    "    Returns:\n",
    "        test_error - the error rate of the classifier (scalar)\n",
    "    \"\"\"\n",
    "    #YOUR CODE HERE\n",
    "    assigned_labels = get_classification(X, theta, temp_parameter)\n",
    "    return 1 - np.mean(np.remainder(assigned_labels, 3) == Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cost_function_over_time(cost_function_history):\n",
    "    plt.plot(range(len(cost_function_history)), cost_function_history)\n",
    "    plt.ylabel('Cost Function')\n",
    "    plt.xlabel('Iteration number')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now suppose that instead we want to retrain our classifier with the new labels. In other words, rather than training the model to predict the original digits and then taking those predictions modulo 3, we explicitly train the model to predict the digits modulo 3 from the original image.\n",
    "\n",
    "How do you expect the performance to change using the new labels?\n",
    " We are trying to find common features of all numbers that have the same mod 3 value, however a lot of them look widely different, so it is harder to separate the data set into 3 groups since, for example, 2 does not share many features with 5 or 8. Therefore one would expect the performance to decrease, and this is what happens.\n",
    " \n",
    " Error rate when trained on labels mod 3: 0.1872"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_softmax_on_MNIST_mod3_x(temp_parameter=1):\n",
    "    \"\"\"\n",
    "    Trains Softmax regression on digit (mod 3) classifications.\n",
    "    See run_softmax_on_MNIST for more info.\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    train_x, train_y, test_x, test_y = get_MNIST_data()\n",
    "    train_y_mod3, test_y_mod3 = update_y(train_y, test_y)\n",
    "    theta, cost_function_history = softmax_regression(train_x, train_y_mod3, temp_parameter, alpha=0.3, lambda_factor=1.0e-4, k=10, num_iterations=150)\n",
    "    plot_cost_function_over_time(cost_function_history)\n",
    "    test_error = compute_test_error_mod3(test_x, test_y_mod3, theta, temp_parameter)\n",
    "    # Save the model parameters theta obtained from calling softmax_regression to disk.\n",
    "    write_pickle_data(theta, \"./theta.pkl.gz\")\n",
    "\n",
    "    # TODO: add your code here for the \"Using the Current Model\" question in tab 4.\n",
    "    #      and print the test_error_mod3\n",
    "    return test_error\n",
    "\n",
    "print('Error of Softmax regression on digit (mod 3) classifications.', run_softmax_on_MNIST_mod3_x(temp_parameter=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Using Manually Crafted Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_data(X):\n",
    "    feature_means = X.mean(axis=0)\n",
    "    return (X - feature_means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_onto_PC(X, pcs, n_components, feature_means):\n",
    "    \"\"\"\n",
    "    Given principal component vectors pcs = principal_components(X)\n",
    "    this function returns a new data array in which each sample in X\n",
    "    has been projected onto the first n_components principcal components.\n",
    "    \"\"\"\n",
    "    centered_data = X - feature_means\n",
    "    return np.dot(centered_data, pcs[:, range(n_components)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def principal_components(centered_data):\n",
    "    scatter_matrix = np.dot(centered_data.transpose(), centered_data)\n",
    "    eigen_values, eigen_vectors = np.linalg.eig(scatter_matrix)\n",
    "    # Re-order eigenvectors by eigenvalue magnitude:\n",
    "    idx = eigen_values.argsort()[::-1]\n",
    "    eigen_values = eigen_values[idx]\n",
    "    eigen_vectors = eigen_vectors[:, idx]\n",
    "    return eigen_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_test_error(X, Y, theta, temp_parameter):\n",
    "    error_count = 0.\n",
    "    assigned_labels = get_classification(X, theta, temp_parameter)\n",
    "    return 1 - np.mean(assigned_labels == Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 18\n",
    "\n",
    "###Correction note:  the following 4 lines have been modified since release.\n",
    "\n",
    "train_x_centered, feature_means = center_data(train_x)\n",
    "pcs = principal_components(train_x_centered)\n",
    "train_pca = project_onto_PC(train_x, pcs, n_components, feature_means)\n",
    "test_pca = project_onto_PC(test_x, pcs, n_components, feature_means)\n",
    "theta, cost_function_history = softmax_regression(train_pca, train_y, temp_parameter=1, alpha=0.3, lambda_factor=1.0e-4, k=10, num_iterations=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_test_error(test_pca, test_y, theta, temp_parameter=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_PC(X, pcs, labels, feature_means):\n",
    "    \"\"\"\n",
    "    Given the principal component vectors as the columns of matrix pcs,\n",
    "    this function projects each sample in X onto the first two principal components\n",
    "    and produces a scatterplot where points are marked with the digit depicted in\n",
    "    the corresponding image.\n",
    "    labels = a numpy array containing the digits corresponding to each image in X.\n",
    "    \"\"\"\n",
    "    pc_data = project_onto_PC(X, pcs, n_components=2, feature_means=feature_means)\n",
    "    text_labels = [str(z) for z in labels.tolist()]\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(pc_data[:, 0], pc_data[:, 1], alpha=0, marker=\".\")\n",
    "    for i, txt in enumerate(text_labels):\n",
    "        ax.annotate(txt, (pc_data[i, 0], pc_data[i, 1]))\n",
    "    ax.set_xlabel('PC 1')\n",
    "    ax.set_ylabel('PC 2')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dimensionality reduction via PCA ##\n",
    "\n",
    "# TODO: First fill out the PCA functions in features.py as the below code depends on them.\n",
    "\n",
    "\n",
    "n_components = 18\n",
    "\n",
    "###Correction note:  the following 4 lines have been modified since release.\n",
    "train_x_centered, feature_means = center_data(train_x)\n",
    "pcs = principal_components(train_x_centered)\n",
    "train_pca = project_onto_PC(train_x, pcs, n_components, feature_means)\n",
    "test_pca = project_onto_PC(test_x, pcs, n_components, feature_means)\n",
    "\n",
    "# train_pca (and test_pca) is a representation of our training (and test) data\n",
    "# after projecting each example onto the first 18 principal components.\n",
    "\n",
    "\n",
    "# TODO: Train your softmax regression model using (train_pca, train_y)\n",
    "#       and evaluate its accuracy on (test_pca, test_y).\n",
    "\n",
    "\n",
    "# TODO: Use the plot_PC function in features.py to produce scatterplot\n",
    "#       of the first 100 MNIST images, as represented in the space spanned by the\n",
    "#       first 2 principal components found above.\n",
    "plot_PC(train_x[range(0, 100), ], pcs, train_y[range(0, 100)], feature_means)#feature_means added since release\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cubic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cubic_features(X):\n",
    "    \"\"\"\n",
    "    Returns a new dataset with features given by the mapping\n",
    "    which corresponds to the cubic kernel.\n",
    "    \"\"\"\n",
    "    n, d = X.shape  # dataset size, input dimension\n",
    "    X_withones = np.ones((n, d + 1))\n",
    "    X_withones[:, :-1] = X\n",
    "    new_d = 0  # dimension of output\n",
    "    new_d = int((d + 1) * (d + 2) * (d + 3) / 6)\n",
    "\n",
    "    new_data = np.zeros((n, new_d))\n",
    "    col_index = 0\n",
    "    for x_i in range(n):\n",
    "        X_i = X[x_i]\n",
    "        X_i = X_i.reshape(1, X_i.size)\n",
    "\n",
    "        if d > 2:\n",
    "            comb_2 = np.matmul(np.transpose(X_i), X_i)\n",
    "\n",
    "            unique_2 = comb_2[np.triu_indices(d, 1)]\n",
    "            unique_2 = unique_2.reshape(unique_2.size, 1)\n",
    "            comb_3 = np.matmul(unique_2, X_i)\n",
    "            keep_m = np.zeros(comb_3.shape)\n",
    "            index = 0\n",
    "            for i in range(d - 1):\n",
    "                keep_m[index + np.arange(d - 1 - i), i] = 0\n",
    "\n",
    "                tri_keep = np.triu_indices(d - 1 - i, 1)\n",
    "\n",
    "                correct_0 = tri_keep[0] + index\n",
    "                correct_1 = tri_keep[1] + i + 1\n",
    "\n",
    "                keep_m[correct_0, correct_1] = 1\n",
    "                index += d - 1 - i\n",
    "\n",
    "            unique_3 = np.sqrt(6) * comb_3[np.nonzero(keep_m)]\n",
    "\n",
    "            new_data[x_i, np.arange(unique_3.size)] = unique_3\n",
    "            col_index = unique_3.size\n",
    "\n",
    "    for i in range(n):\n",
    "        newdata_colindex = col_index\n",
    "        for j in range(d + 1):\n",
    "            new_data[i, newdata_colindex] = X_withones[i, j]**3\n",
    "            newdata_colindex += 1\n",
    "            for k in range(j + 1, d + 1):\n",
    "                new_data[i, newdata_colindex] = X_withones[i, j]**2 * X_withones[i, k] * (3**(0.5))\n",
    "                newdata_colindex += 1\n",
    "\n",
    "                new_data[i, newdata_colindex] = X_withones[i, j] * X_withones[i, k]**2 * (3**(0.5))\n",
    "                newdata_colindex += 1\n",
    "\n",
    "                if k < d:\n",
    "                    new_data[i, newdata_colindex] = X_withones[i, j] * X_withones[i, k] * (6**(0.5))\n",
    "                    newdata_colindex += 1\n",
    "\n",
    "    return new_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 18\n",
    "train_x_centered, feature_means = center_data(train_x)\n",
    "pcs = principal_components(train_x_centered)\n",
    "train_pca = project_onto_PC(train_x, pcs, n_components, feature_means)\n",
    "test_pca = project_onto_PC(test_x, pcs, n_components, feature_means)\n",
    "\n",
    "train_pca10 = train_pca[:,:10]\n",
    "test_pca10 = test_pca[:,:10]\n",
    "# TODO: First fill out cubicFeatures() function in features.py as the below code requires it.\n",
    "\n",
    "train_cube = cubic_features(train_pca10)\n",
    "test_cube = cubic_features(test_pca10)\n",
    "# train_cube (and test_cube) is a representation of our training (and test) data\n",
    "# after applying the cubic kernel feature mapping to the 10-dimensional PCA representations.\n",
    "\n",
    "\n",
    "# TODO: Train your softmax regression model using (train_cube, train_y)\n",
    "#       and evaluate its accuracy on (test_cube, test_y).\n",
    "theta, cost_function_history = softmax_regression(train_cube, train_y, temp_parameter=1, alpha=0.3, lambda_factor=1.0e-4, k=10, num_iterations=150)\n",
    "test_error = compute_test_error(test_cube, test_y, theta, temp_parameter=1)\n",
    "print('softmax classification error using pca10 with cubic feature representation',test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clfpoly = SVC(kernel='poly', random_state = 0, degree=3)\n",
    "\n",
    "n_components = 18\n",
    "\n",
    "feature_means = train_x.mean(axis=0)\n",
    "\n",
    "train_x_centered = center_data(train_x)\n",
    "pcs = principal_components(train_x_centered)\n",
    "\n",
    "train_pca = project_onto_PC(train_x, pcs, n_components, feature_means)\n",
    "test_pca = project_onto_PC(test_x, pcs, n_components, feature_means)\n",
    "\n",
    "\n",
    "train_pca10 = train_pca[:,:10]\n",
    "test_pca10 = test_pca[:,:10]\n",
    "\n",
    "clfpoly.fit(train_pca10, train_y)\n",
    "zpoly = clfpoly.predict(test_pca10)\n",
    "test_error = 1 - np.mean(zpoly == test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07350000000000001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06359999999999999\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "clfpoly = SVC(kernel='rbf', random_state = 0)\n",
    "\n",
    "n_components = 18\n",
    "\n",
    "feature_means = train_x.mean(axis=0)\n",
    "\n",
    "train_x_centered = center_data(train_x)\n",
    "pcs = principal_components(train_x_centered)\n",
    "\n",
    "train_pca = project_onto_PC(train_x, pcs, n_components, feature_means)\n",
    "test_pca = project_onto_PC(test_x, pcs, n_components, feature_means)\n",
    "\n",
    "\n",
    "train_pca10 = train_pca[:,:10]\n",
    "test_pca10 = test_pca[:,:10]\n",
    "\n",
    "\n",
    "clfpoly.fit(train_pca10, train_y)\n",
    "zpoly = clfpoly.predict(test_pca10)\n",
    "test_error = 1 - np.mean(zpoly == test_y)\n",
    "print(test_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
